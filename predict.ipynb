{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1956a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.data_loading import BasicDataset\n",
    "from unet import UNet\n",
    "from utils.utils import plot_img_and_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549c122d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (inc): DoubleConv(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (down1): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down2): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down3): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (down4): Down(\n",
       "    (maxpool_conv): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "      (1): DoubleConv(\n",
       "        (double_conv): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (5): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up1): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up2): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up3): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (up4): Up(\n",
       "    (up): Upsample(scale_factor=2.0, mode=bilinear)\n",
       "    (conv): DoubleConv(\n",
       "      (double_conv): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (5): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (outc): OutConv(\n",
       "    (conv): Conv2d(64, 2, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UNet(n_channels=3, n_classes=2, bilinear=True)\n",
    "model.load_state_dict(torch.load(\"./checkpoints/checkpoint_epoch5.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca5f14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_img(net,\n",
    "                full_img,\n",
    "                device,\n",
    "                scale_factor=1,\n",
    "                out_threshold=0.5):\n",
    "    net.eval()\n",
    "    img = torch.from_numpy(BasicDataset.preprocess(full_img, scale_factor, is_mask=False))\n",
    "    img = img.unsqueeze(0)\n",
    "    img = img.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = net(img)\n",
    "\n",
    "        if net.n_classes > 1:\n",
    "            probs = F.softmax(output, dim=1)[0]\n",
    "        else:\n",
    "            probs = torch.sigmoid(output)[0]\n",
    "\n",
    "        tf = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((full_img.size[1], full_img.size[0])),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "        full_mask = tf(probs.cpu()).squeeze()\n",
    "\n",
    "    if net.n_classes == 1:\n",
    "        return (full_mask > out_threshold).numpy()\n",
    "    else:\n",
    "        return F.one_hot(full_mask.argmax(dim=0), net.n_classes).permute(2, 0, 1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93adadd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_filenames(args):\n",
    "    def _generate_name(fn):\n",
    "        split = os.path.splitext(fn)\n",
    "        return f'{split[0]}_OUT{split[1]}'\n",
    "\n",
    "    return args.output or list(map(_generate_name, args.input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0958e716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_to_image(mask: np.ndarray):\n",
    "    if mask.ndim == 2:\n",
    "        return Image.fromarray((mask * 255).astype(np.uint8))\n",
    "    elif mask.ndim == 3:\n",
    "        return Image.fromarray((np.argmax(mask, axis=0) * 255 / mask.shape[0]).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d9d4516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(input, output, model, scale, mask_threshold, no_save):\n",
    "    in_files = input\n",
    "    out_files = output\n",
    "\n",
    "    net = UNet(n_channels=3, n_classes=2)\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    logging.info(f'Loading model {model}')\n",
    "    logging.info(f'Using device {device}')\n",
    "\n",
    "    net.to(device=device)\n",
    "    net.load_state_dict(torch.load(model, map_location=device))\n",
    "\n",
    "    logging.info('Model loaded!')\n",
    "\n",
    "    for i, filename in enumerate(in_files):\n",
    "        logging.info(f'\\nPredicting image {filename} ...')\n",
    "        img = Image.open(filename)\n",
    "\n",
    "        mask = predict_img(net=net,\n",
    "                           full_img=img,\n",
    "                           scale_factor=scale,\n",
    "                           out_threshold=mask_threshold,\n",
    "                           device=device)\n",
    "\n",
    "#         result_mask = mask_to_image(mask)\n",
    "#         imgplot = plt.imshow(result_mask)\n",
    "#         plt.show()\n",
    "        \n",
    "        if not no_save:\n",
    "            out_filename = out_files[i]\n",
    "            result = mask_to_image(mask)\n",
    "            imgplot = plt.imshow(result)\n",
    "            result.save(out_filename)\n",
    "            logging.info(f'Mask saved to {out_filename}')\n",
    "\n",
    "        if viz:\n",
    "            logging.info(f'Visualizing results for image {filename}, close to continue...')\n",
    "#             plot_img_and_mask(img, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c2cb0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelPath = \"./checkpoints/checkpoint_epoch5.pth\"\n",
    "input = [\"/data/datasets/clothing-size/train/imgs/IMG_9346.jpg\"]\n",
    "output = [\"./prediction.jpg\"]\n",
    "viz = True\n",
    "# Do not save the output masks\n",
    "no_save = False\n",
    "mask_hreshold =0.5\n",
    "scale = 0.33\n",
    "\n",
    "get_predictions(input, output, modelPath, scale, mask_hreshold, no_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
