{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73079e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/milesial/Pytorch-UNet.git\n",
    "# Fix for cuda init error\n",
    "#!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538243f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.clothing_dataset import BasicDataset, ClothingDataset\n",
    "from utils.dice_score import dice_loss\n",
    "from utils.evaluate import evaluate\n",
    "from unet import UNet\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053fd727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.cuda\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a8f64e",
   "metadata": {},
   "source": [
    "# Setup wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13a57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project='unet', entity='endev')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed709626",
   "metadata": {},
   "source": [
    "# Dataset Path Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f277d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"./data/\"\n",
    "dir_checkpoint = Path('./training/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5102ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir_img = Path('/data/datasets/clothing-size/train/imgs/')\n",
    "train_dir_mask = Path('/data/datasets/clothing-size/train/mask/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603114bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dir_img = Path('/data/datasets/clothing-size/val/imgs/')\n",
    "val_dir_mask = Path('/data/datasets/clothing-size/val/mask/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb3eb47",
   "metadata": {},
   "source": [
    "# Check data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10af3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /data/datasets/clothing-size/val/imgs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9611a227",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /data/datasets/clothing-size/val/mask/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda86544",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net,\n",
    "              device,\n",
    "              epochs: int = 5,\n",
    "              batch_size: int = 1,\n",
    "              learning_rate: float = 0.001,\n",
    "              save_checkpoint: bool = True,\n",
    "              img_scale: float = 0.5,\n",
    "              amp: bool = False):\n",
    "    # 1. Create dataset\n",
    "    train_dataset = ClothingDataset(train_dir_img, train_dir_mask, img_scale)\n",
    "    val_dataset = ClothingDataset(val_dir_img, val_dir_mask, img_scale)\n",
    "\n",
    "    # 2. Totals\n",
    "    n_train = len(train_dataset)\n",
    "    n_val = len(val_dataset)\n",
    "\n",
    "    # 3. Create data loaders\n",
    "    loader_args = dict(batch_size=batch_size, num_workers=1, pin_memory=True)\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, **loader_args)\n",
    "    val_loader = DataLoader(val_dataset, shuffle=False, drop_last=True, **loader_args)\n",
    "\n",
    "    # (Initialize logging)\n",
    "    experiment = wandb.init(project='U-Net-mask', resume='allow', anonymous='must')\n",
    "    experiment.config.update(dict(epochs=epochs, \n",
    "                                  batch_size=batch_size, \n",
    "                                  learning_rate=learning_rate,\n",
    "                                  save_checkpoint=save_checkpoint, \n",
    "                                  img_scale=img_scale,\n",
    "                                  amp=amp))\n",
    "    logging.info(f'''Starting training:\n",
    "        Epochs:          {epochs}\n",
    "        Batch size:      {batch_size}\n",
    "        Learning rate:   {learning_rate}\n",
    "        Training size:   {n_train}\n",
    "        Validation size: {n_val}\n",
    "        Checkpoints:     {save_checkpoint}\n",
    "        Device:          {device.type}\n",
    "        Images scaling:  {img_scale}\n",
    "        Mixed Precision: {amp}\n",
    "    ''')\n",
    "\n",
    "    # 4. Set up the optimizer, the loss, the learning rate scheduler and the loss scaling for AMP\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', patience=2)  # goal: maximize Dice score\n",
    "    grad_scaler = torch.cuda.amp.GradScaler(enabled=amp)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    global_step = 0\n",
    "\n",
    "    # 5. Begin training\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        epoch_loss = 0\n",
    "        with tqdm(total=n_train, desc=f'Epoch {epoch + 1}/{epochs}', unit='img') as pbar:\n",
    "            for batch in train_loader:\n",
    "                images = batch['image']\n",
    "                true_masks = batch['mask']\n",
    "\n",
    "                assert images.shape[1] == net.n_channels, \\\n",
    "                    f'Network has been defined with {net.n_channels} input channels, ' \\\n",
    "                    f'but loaded images have {images.shape[1]} channels. Please check that ' \\\n",
    "                    'the images are loaded correctly.'\n",
    "\n",
    "                images = images.to(device=device, dtype=torch.float32)\n",
    "                true_masks = true_masks.to(device=device, dtype=torch.long)\n",
    "\n",
    "                with torch.cuda.amp.autocast(enabled=amp):\n",
    "                    masks_pred = net(images)\n",
    "                    loss = criterion(masks_pred, true_masks) \\\n",
    "                           + dice_loss(F.softmax(masks_pred, dim=1).float(),\n",
    "                                       F.one_hot(true_masks, net.n_classes).permute(0, 3, 1, 2).float(),\n",
    "                                       multiclass=True)\n",
    "\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                grad_scaler.scale(loss).backward()\n",
    "                grad_scaler.step(optimizer)\n",
    "                grad_scaler.update()\n",
    "\n",
    "                pbar.update(images.shape[0])\n",
    "                global_step += 1\n",
    "                epoch_loss += loss.item()\n",
    "                experiment.log({\n",
    "                    'train loss': loss.item(),\n",
    "                    'step': global_step,\n",
    "                    'epoch': epoch\n",
    "                })\n",
    "                \n",
    "                pbar.set_postfix(**{'loss (batch)': loss.item()})\n",
    "\n",
    "                # Evaluation round\n",
    "                if global_step % (n_train // (2 * batch_size)) == 0:\n",
    "                    histograms = {}\n",
    "                    for tag, value in net.named_parameters():\n",
    "                        tag = tag.replace('/', '.')\n",
    "                        histograms['Weights/' + tag] = wandb.Histogram(value.data.cpu())\n",
    "                        histograms['Gradients/' + tag] = wandb.Histogram(value.grad.data.cpu())\n",
    "\n",
    "                    val_score = evaluate(net, val_loader, device)\n",
    "                    scheduler.step(val_score)\n",
    "\n",
    "                    logging.info('Validation Dice score: {}'.format(val_score))\n",
    "                    experiment.log({\n",
    "                        'learning rate': optimizer.param_groups[0]['lr'],\n",
    "                        'validation Dice': val_score,\n",
    "                        'images': wandb.Image(images[0].cpu()),\n",
    "                        'masks': {\n",
    "                            'true': wandb.Image(true_masks[0].float().cpu()),\n",
    "                            'pred': wandb.Image(torch.softmax(masks_pred, dim=1)[0].float().cpu()),\n",
    "                        },\n",
    "                        'step': global_step,\n",
    "                        'epoch': epoch,\n",
    "                        **histograms\n",
    "                    })\n",
    "\n",
    "        if save_checkpoint:\n",
    "            Path(dir_checkpoint).mkdir(parents=True, exist_ok=True)\n",
    "            torch.save(net.state_dict(), str(dir_checkpoint / 'checkpoint_epoch{}_{}.pth'.format(epoch, datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\"))))\n",
    "            logging.info(f'Checkpoint {epoch + 1} saved at {datetime.now().strftime(\"%m_%d_%Y_%H_%M_%S\")}!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47355468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs\n",
    "epochs = 50\n",
    "\n",
    "# Batch size\n",
    "batch_size=1\n",
    "\n",
    "# Learning rate\n",
    "lr = 0.0001\n",
    "\n",
    "# Load model from a .pth file\n",
    "load = False\n",
    "\n",
    "# Downscaling factor of the image\n",
    "scale = 1\n",
    "\n",
    "# Use mixed precision\n",
    "amp = False\n",
    "\n",
    "weight_decay=1e-8\n",
    "\n",
    "momentum=0.9\n",
    "\n",
    "config = wandb.config\n",
    "config.epochs = epochs\n",
    "config.batch_size = batch_size\n",
    "config.lr = lr\n",
    "config.load = load\n",
    "config.scale = scale\n",
    "config.amp = amp\n",
    "config.weight_decay = weight_decay\n",
    "config.momentum = momentum\n",
    "\n",
    "config.model = \"Unet-mask\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b969b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logging.info(f'Using device {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d3f23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = UNet(n_channels=3, n_classes=2, bilinear=True)\n",
    "net.to(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d0d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.info(f'Network:\\n'\n",
    "                 f'\\t{net.n_channels} input channels\\n'\n",
    "                 f'\\t{net.n_classes} output channels (classes)\\n'\n",
    "                 f'\\t{\"Bilinear\" if net.bilinear else \"Transposed conv\"} upscaling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212d8bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7333523e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    train_net(net=net,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              learning_rate=lr,\n",
    "              device=device,\n",
    "              img_scale=scale,\n",
    "              amp=amp)\n",
    "except KeyboardInterrupt:\n",
    "    torch.save(net.state_dict(), 'INTERRUPTED.pth')\n",
    "    logging.info('Saved interrupt')\n",
    "    sys.exit(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
